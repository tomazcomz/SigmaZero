{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project – Developing an Alpha Zero Game Player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratory of Artificial Intelligence and Data Science\n",
    "\n",
    "#### TP1 - Group 7:\n",
    "##### Anna Sellani\n",
    "##### Gonçalo Dias\n",
    "##### Tomás Azevedo\n",
    "##### Vicente Bandeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [\"A4x4\", \"A5x5\", \"A6x6\", \"G7x7\", \"G9x9\"]\n",
    "game = games[0]     # ATTAXX\n",
    "game = games[3]     # GO\n",
    "\n",
    "INVALID_LIMIT = 2\n",
    "TIME_LIMIT = 10  # (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_move_valid_go(game,move):    # implementing the logic to check if the move is valid\n",
    "    return move in check_possible_moves(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_server_go(host='localhost', port=12345):\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(2)\n",
    "\n",
    "    print(\"Waiting for two agents to connect...\")\n",
    "    agent1, addr1 = server_socket.accept()\n",
    "    print(\"Agent 1 connected from\", addr1)\n",
    "    bs=b'AG1 '+game.encode()\n",
    "    agent1.sendall(bs)\n",
    "\n",
    "    agent2, addr2 = server_socket.accept()\n",
    "    print(\"Agent 2 connected from\", addr2)\n",
    "    bs=b'AG2 '+game.encode()\n",
    "    agent2.sendall(bs)\n",
    "       \n",
    "    n = int(game[1])\n",
    "    initial_board = np.zeros((n, n),dtype=int)     # initializing an empty board of size (n x n)\n",
    "    GameState = Go(initial_board)    # initializing the game\n",
    "    \n",
    "    pygame.init()\n",
    "    screen = set_screen_go()    # setting the screen for graphical display\n",
    "    draw_board_go(GameState, screen)\n",
    "    pygame.display.update()\n",
    "\n",
    "    agents = [agent1, agent2]\n",
    "    current_agent = 0\n",
    "\n",
    "    jog=0\n",
    "    invalid_count = 0   # consecutive invalid moves count \n",
    "    \n",
    "    time.sleep(3)\n",
    "    while True:\n",
    "        try:\n",
    "            data = None\n",
    "            data = agents[current_agent].recv(1024).decode()\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            if data == \"PASS\":\n",
    "                agents[current_agent].sendall(b'VALID')\n",
    "                agents[1-current_agent].sendall(data.encode())\n",
    "                GameState.pass_turn()\n",
    "            else:\n",
    "                # processing the move (example: \"MOVE X,Y\")\n",
    "                i = int(data[5])\n",
    "                j = int(data[7])\n",
    "                if current_agent == 0:\n",
    "                    print(\"Agent 1 -> \",data)\n",
    "                else:\n",
    "                    print(\"Agent 2 -> \",data)\n",
    "                jog = jog+1\n",
    "                \n",
    "                # checking if the move is valid and, if so, executing it\n",
    "                if is_move_valid_go(GameState,(i,j)):\n",
    "                    agents[current_agent].sendall(b'VALID')\n",
    "                    agents[1-current_agent].sendall(data.encode())\n",
    "                    GameState = GameState.move((i,j))\n",
    "                    time.sleep(0.1)\n",
    "                    draw_board_go(GameState, screen)\n",
    "                    draw_pieces_go(GameState, screen)\n",
    "                    event = pygame.event.poll()\n",
    "                else:\n",
    "                    agents[current_agent].sendall(b'INVALID')\n",
    "                    invalid_count += 1\n",
    "                    if invalid_count < INVALID_LIMIT:   # if invalid count reaches 5, then the agent passes\n",
    "                        continue\n",
    "                    agents[current_agent].sendall(b'TURN LOSS')\n",
    "                    agents[1-current_agent].sendall(b'PASS')\n",
    "                    GameState = GameState.pass_turn()\n",
    "                    invalid_count = 0\n",
    "                \n",
    "            pygame.display.update()\n",
    "                \n",
    "            # checking if the game is over\n",
    "            if is_game_finished_go(GameState):\n",
    "                GameState.end_game()\n",
    "                winner = GameState.winner\n",
    "                if winner == -1:\n",
    "                    winner = 2\n",
    "                p1_score = GameState.scores[1]\n",
    "                p2_score = GameState.scores[-1]\n",
    "                data = \"END \" + str(winner) + \" \" + str(p1_score) + \" \" + str(p2_score)\n",
    "                agents[current_agent].sendall(data.encode())\n",
    "                agents[1-current_agent].sendall(data.encode())\n",
    "                draw_result_go(GameState, screen)\n",
    "                pygame.display.update()\n",
    "                time.sleep(4)\n",
    "                pygame.quit()\n",
    "                break\n",
    "                \n",
    "            # Switch to the other agent\n",
    "            current_agent = 1-current_agent\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            break\n",
    "\n",
    "    print(\"\\n-----------------\\nGAME END\\n-----------------\\n\")\n",
    "    time.sleep(1)\n",
    "    agent1.close()\n",
    "    agent2.close()\n",
    "    server_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_board_attaxx(n):\n",
    "    board = np.zeros((n, n),dtype=int)\n",
    "    board[0][0] = board[n-1][n-1] = 1\n",
    "    board[n-1][0] = board[0][n-1] = -1\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_move_valid_attaxx(GameState,i,j,i2,j2):\n",
    "    possible_moves = [(1,0),(2,0),(1,1),(2,2),(1,-1),(2,-2),(-1,0),(-2,0),(-1,1),(-2,-2),(0,1),(0,2),(0,-1),(0,-2),(-1,-1),(-2,2)]\n",
    "    move = (i2-i,j2-j)\n",
    "    if move not in possible_moves:\n",
    "        return False\n",
    "    moves = get_moves(GameState,(i,j))\n",
    "    return moves[move][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_server_attaxx(host='localhost', port=12345):\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(2)\n",
    "\n",
    "    print(\"Waiting for two agents to connect...\")\n",
    "    agent1, addr1 = server_socket.accept()\n",
    "    print(\"Agent 1 connected from\", addr1)\n",
    "    bs=b'AG1 '+game.encode()\n",
    "    agent1.sendall(bs)\n",
    "\n",
    "    agent2, addr2 = server_socket.accept()\n",
    "    print(\"Agent 2 connected from\", addr2)\n",
    "    bs=b'AG2 '+game.encode()\n",
    "    agent2.sendall(bs)\n",
    "       \n",
    "    n = int(game[1])\n",
    "    initial_board = create_board_attaxx(n)     # initializing an empty board of size (n x n)\n",
    "    GameState = Attaxx(initial_board)    # initializing the game\n",
    "\n",
    "    pygame.init()\n",
    "    screen = set_screen_attaxx()    # setting the screen for graphical display\n",
    "    draw_board_attaxx(GameState, screen)\n",
    "    draw_pieces_attaxx(GameState, screen)\n",
    "    pygame.display.update()\n",
    "\n",
    "    agents = [agent1, agent2]\n",
    "    current_agent = 0\n",
    "    player_id = 1\n",
    "\n",
    "    jog=0\n",
    "    invalid_count = 0   # consecutive invalid moves count \n",
    "    \n",
    "    time.sleep(3)\n",
    "    while True:\n",
    "        try:\n",
    "            data = None\n",
    "            data = agents[current_agent].recv(1024).decode()\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            # processing the move (example: \"MOVE X,Y,X2,Y2\")\n",
    "            i = int(data[5])\n",
    "            j = int(data[7])\n",
    "            i2 = int(data[9])\n",
    "            j2 = int(data[11])\n",
    "            if current_agent == 0:\n",
    "                print(\"Agent 1 -> \",data)\n",
    "            else:\n",
    "                print(\"Agent 2 -> \",data)\n",
    "            jog = jog+1\n",
    "            \n",
    "            # checking if the move is valid and, if so, executing it\n",
    "            if is_move_valid_attaxx(GameState,i,j,i2,j2):\n",
    "                agents[current_agent].sendall(b'VALID')\n",
    "                agents[1-current_agent].sendall(data.encode())\n",
    "                GameState = execute_move(GameState,(i,j),(i2,j2),player_id=player_id)\n",
    "                time.sleep(0.1)\n",
    "                draw_board_attaxx(GameState, screen)\n",
    "                draw_pieces_attaxx(GameState, screen)\n",
    "                event = pygame.event.poll()\n",
    "            else:\n",
    "                invalid_count += 1\n",
    "                if invalid_count < INVALID_LIMIT:   # if invalid count reaches 5, then the agent passes\n",
    "                    agents[current_agent].sendall(b'INVALID')\n",
    "                    continue\n",
    "                agents[current_agent].sendall(b'TURN LOSS')\n",
    "                agents[1-current_agent].sendall(b'PASS')\n",
    "                GameState.switchPlayer()\n",
    "                invalid_count = 0\n",
    "\n",
    "            pygame.display.update()\n",
    "\n",
    "            # checking if the game is over\n",
    "            value,score1,score2 = is_game_finished_attaxx(GameState,player=player_id)   # -1 if game is not over, 0 if it's a draw, 1 if player 1 won and 2 if player 2 won \n",
    "            if value != -2:\n",
    "                result = value\n",
    "                if result == 1:\n",
    "                    p1_score = score1\n",
    "                    p2_score = score2\n",
    "                else:\n",
    "                    p2_score = score1\n",
    "                    p1_score = score2\n",
    "                data = \"END \" + str(result) + \" \" + str(p1_score) + \" \" + str(p2_score)\n",
    "                agents[current_agent].sendall(data.encode())\n",
    "                agents[1-current_agent].sendall(data.encode())\n",
    "                draw_result_attaxx(GameState, screen)\n",
    "                pygame.display.update()\n",
    "                time.sleep(4)\n",
    "                pygame.quit()\n",
    "                break\n",
    "                \n",
    "            # Switch to the other agent\n",
    "            current_agent = 1-current_agent\n",
    "            player_id = 0-player_id\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            break\n",
    "\n",
    "    print(\"\\n-----------------\\nGAME END\\n-----------------\\n\")\n",
    "    time.sleep(1)\n",
    "    agent1.close()\n",
    "    agent2.close()\n",
    "    server_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if game[0]=='G':\n",
    "        start_server_go()\n",
    "    elif game[0]=='A':\n",
    "        start_server_attaxx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from go.inputconverter import *\n",
    "import time\n",
    "import decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select, expand and evaluate, backup, play<br/>\n",
    "<br/>\n",
    "APV-MCTS variant <br/>\n",
    "<br/>\n",
    "N = visit_count<br/>\n",
    "W = total_action_value<br/>\n",
    "Q = mean_action_value<br/>\n",
    "P = prior_prob of selecting that edge<br/>\n",
    "exploration constant = cpuct <br/>\n",
    "<br/>\n",
    "Q = W/N # controlls exploitation<br/>\n",
    "U = cput*p*(math.sqrt(sum_N)/(1+N)) # controlls exploration<br/>\n",
    "<br/>\n",
    "edges (moves)<br/>\n",
    "nodes (positions/states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game_state, args, mcts, parent=None, p_action=None, prior_prob=0,play_idx=0):\n",
    "        self.game_state=game_state\n",
    "        self.args=args\n",
    "        self.parent=parent\n",
    "        self.p_action=p_action\n",
    "        self.prior_prob=prior_prob  # P\n",
    "        self.children=[]\n",
    "        self.visit_count=0  # N\n",
    "        self.total_action_value=0   # W\n",
    "        self.possible=self.game_state.n**2+self.game_state.type\n",
    "        self.mcts=mcts\n",
    "        self.play_idx=play_idx\n",
    "\n",
    "    def fully_expanded(self):\n",
    "        return len(self.children)>0     # if no expandable moves and there are children\n",
    "    \n",
    "    def select(self):   # chooses child with best ucb \n",
    "        if not self.fully_expanded():\n",
    "            return self\n",
    "        selected = max(self.children, key=lambda child: self.ucb(child))\n",
    "        return selected.select()\n",
    "    \n",
    "    def cpuct(self, visit_count):   # defining cpuct according to paper\n",
    "        return math.log((visit_count+19652+1)/19652)+self.args['cpuct']\n",
    "    \n",
    "    def ucb(self, child):   # uses variant of the PUCT algorithm\n",
    "        if child is None:       # to avoid 'NoneType' error\n",
    "            return 0\n",
    "        if child.visit_count==0:\n",
    "            mean_action_value=0     \n",
    "        else:\n",
    "            mean_action_value=child.total_action_value/child.visit_count        # mean_action_value Q=W/N\n",
    "        return mean_action_value+self.cpuct(self.visit_count)*child.prior_prob*(math.sqrt(self.visit_count)/(1+child.visit_count))\n",
    "\n",
    "    def expand(self, p):\n",
    "        for _ in range(self.possible):\n",
    "            action=self.mcts.get_act(_)\n",
    "            if action in self.game_state.empty_positions or action==(-1,-1):    # to avoid 'NoneType' error\n",
    "                next_state = self.game_state.move(action)\n",
    "                child = Node(next_state,self.args, parent=self, p_action=action, prior_prob=p[_],mcts=self.mcts,play_idx=self.play_idx+1)\n",
    "                self.children.append(child)\n",
    "    \n",
    "    def backprop(self, v):\n",
    "        self.total_action_value  += v\n",
    "        self.visit_count += 1\n",
    "        if self.parent is not None:\n",
    "            self.parent.backprop(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, game_state, args, model,eva=False):\n",
    "        self.game_state=game_state\n",
    "        self.args=args\n",
    "        self.model=model\n",
    "        self.evaluate=eva\n",
    "        self.ti=self.setind(game_state)\n",
    "        self.root=Node(self.game_state, self.args,self)\n",
    "        self.pi=np.zeros(self.game_state.n**2+self.game_state.type)\n",
    "        self.map=self.map_act()\n",
    "\n",
    "    def setind(self,game):  # temperature according to game and boards\n",
    "        if game.type==0:\n",
    "            match len(game.board):\n",
    "                case 4:\n",
    "                    tind=2\n",
    "                case 6:\n",
    "                    tind=3\n",
    "        else:\n",
    "            match len(game.board):\n",
    "                case 7:\n",
    "                    tind=5\n",
    "                case 9:\n",
    "                    tind=7\n",
    "        return tind\n",
    "    \n",
    "    def map_act(self):  # mapping actions\n",
    "        list=[]\n",
    "        if self.game_state.name=='attaxx':\n",
    "            for i in range(len(self.game_state.board)):\n",
    "                for j in range(len(self.game_state.board[0])):\n",
    "                    list.append((j,i))\n",
    "        else:\n",
    "            for i in range(len(self.game_state.board)):\n",
    "                for j in range(len(self.game_state.board[0])):\n",
    "                    list.append((i,j))\n",
    "            list.append((-1,-1))\n",
    "        return list\n",
    "\n",
    "    def get_act(self,_):\n",
    "        return  self.map[_]\n",
    "    \n",
    "    def cut(self,action):   # new root node is the child corresponding to the played action\n",
    "        for child in self.root.children:\n",
    "            if child.p_action==action:\n",
    "                self.root=child\n",
    "                self.pi=np.zeros(self.game_state.n**2+self.game_state.type)\n",
    "\n",
    "    def printTree(self, node, level=0, prefix=\"\"):  # analysis purposes only\n",
    "        if node is not None:\n",
    "            print(\" \" * level * 2 + f\"{prefix}+- action: {node.p_action}, N: {node.visit_count}, W: {node.total_action_value}\")\n",
    "            for i, child in enumerate(node.children):\n",
    "                self.printTree(child, level + 1, f\"{prefix}|  \" if i < len(node.children) - 1 else f\"{prefix}   \")\n",
    "\n",
    "    def get_play(self,passe=None):  # chooses move based on maximum pi\n",
    "        max_val=0\n",
    "        ind=[]\n",
    "        for i in range(len(self.pi)):\n",
    "            if i==passe:\n",
    "                continue\n",
    "            val=self.pi[i]\n",
    "            if val>max_val:\n",
    "                ind=[i]\n",
    "                max_val=self.pi[i]\n",
    "                continue\n",
    "            if val==max_val:\n",
    "                ind.append(i)\n",
    "        return random.choice(ind)\n",
    "    \n",
    "    def play(self):\n",
    "        for _ in range(self.args['num_searches']):\n",
    "            node=self.root\n",
    "\n",
    "            # selection\n",
    "            while node.fully_expanded():\n",
    "                node=node.select()\n",
    "\n",
    "            # check if node is terminal or not\n",
    "            terminal=self.game_state.is_game_finished()\n",
    "            \n",
    "            # expand and evaluate\n",
    "            if not terminal:\n",
    "                if self.game_state.type==1:\n",
    "                    board=gen_batch(node.game_state)\n",
    "                else:\n",
    "                    board=node.game_state.board\n",
    "                p, v = self.model.net.predict(np.array([board]),batch_size=1,verbose=0)\n",
    "                p=p[0]\n",
    "                v=v[0][0]\n",
    "                if self.root.play_idx-1>self.ti or self.evaluate:\n",
    "                    p=0.75*p+0.25*np.random.dirichlet([0.2,0.2,0.2])[0]     # adding Dirichlet noise to root's prior \n",
    "\n",
    "                node.expand(p)      # adding children with policy from the NN to list children\n",
    "            \n",
    "            # backpropagate\n",
    "            node.backprop(v)\n",
    "\n",
    "        if self.root.play_idx-1<=self.ti and not self.evaluate:\n",
    "            temp=1\n",
    "        else:\n",
    "            temp=10**(-2)\n",
    "\n",
    "        sumb=decimal.Decimal(0)\n",
    "        for child in self.root.children:\n",
    "            if child is None or child.visit_count==0:\n",
    "                continue\n",
    "            else:\n",
    "                sumb+=(decimal.Decimal(child.visit_count)**decimal.Decimal(1/temp))\n",
    "                    \n",
    "        for child in self.root.children:\n",
    "            if child is None:\n",
    "                continue\n",
    "            if child.visit_count == 0:\n",
    "                self.pi[self.map.index(child.p_action)] = 0\n",
    "            elif child.visit_count == 1:\n",
    "                self.pi[self.map.index(child.p_action)] = 0.1\n",
    "            else: \n",
    "                self.pi[self.map.index(child.p_action)] = (float)((decimal.Decimal(child.visit_count)**decimal.Decimal((1/temp)))/(sumb))\n",
    "        \n",
    "        pol=self.pi\n",
    "        max_prob_index=self.get_play()\n",
    "        if max_prob_index == self.game_state.n**2:\n",
    "            self.cut((-1,-1))\n",
    "            return (-1, -1),pol     # define this as \"pass\"\n",
    "        else:\n",
    "            played=((max_prob_index // self.game_state.n), (max_prob_index % self.game_state.n))    # convert 1D array index to 2D array coordinates\n",
    "            print(f\"Play chosen: {played}\")     # analysis purposes only\n",
    "            self.cut(played) \n",
    "            return played,pol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers,regularizers,optimizers\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import os, random\n",
    "import names\n",
    "from go.inputconverter import *\n",
    "from shutil import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neura:\n",
    "    def __init__(self,game,name=None): \n",
    "        self.input(game)\n",
    "        self.game=game\n",
    "        self.res=19\n",
    "        self.build(self.res,self.nf)\n",
    "        if name=='acacio':                          # for alternative approach testing\n",
    "            self.name='acacio'+game.name+str(len(game.board))+str(self.res)\n",
    "        elif name==None:\n",
    "            self.name=names.get_last_name()+game.name+str(len(game.board))+str(self.res)\n",
    "            self.net.save_weights(f'modelos/{game.name}/{str(len(game.board))}/{self.name}.h5')\n",
    "        else:\n",
    "            self.name=name\n",
    "            self.net.load_weights(f'modelos/{game.name}/{str(len(game.board))}/{self.name}.h5')\n",
    "        \n",
    "\n",
    "    def input(self,game):\n",
    "        if (game.type==0):\n",
    "            self.nf=math.ceil(len(game.board)**2*0.709+len(game.board)**2)                 \n",
    "            self.inpt=layers.Input(shape=(len(game.board),len(game.board[0]),1))\n",
    "            self.passes=0\n",
    "        else:\n",
    "            self.nf=math.ceil(len(game.board)**2*0.709+len(game.board)**2)\n",
    "            self.passes=1\n",
    "            self.inpt=layers.Input((len(game.board),len(game.board[0]),17))\n",
    "        self.action_space=len(game.board)*len(game.board[0])+self.passes\n",
    "\n",
    "    def convblock(self,input,nf):\n",
    "        c=layers.Conv2D(nf,3,(1,1),'same',kernel_regularizer=regularizers.L2(0.0001))(input)\n",
    "        b=layers.BatchNormalization()(c)\n",
    "        rnl=layers.Activation(activation='softplus')(b)\n",
    "        return rnl\n",
    "\n",
    "    def resblock(self,input,i,nf):\n",
    "        cb=self.convblock(input,nf)\n",
    "        c=layers.Conv2D(nf,3,(1,1),'same',kernel_regularizer=regularizers.L2(0.0001))(cb)\n",
    "        b=layers.BatchNormalization()(c)\n",
    "        s=layers.Add()([b,input])\n",
    "        rnl=layers.Activation(activation='softplus',name=f'endrestower{i}')(s)\n",
    "        return rnl\n",
    "    \n",
    "    def polhead(self,input):\n",
    "        c=layers.Conv2D(2,1,(1,1),'same',name='convpol',kernel_regularizer=regularizers.L2(0.0001))(input)\n",
    "        b=layers.BatchNormalization(name='bnpol')(c)\n",
    "        rnl=layers.Activation(activation='softplus',name='rnlpol')(b)\n",
    "        flt=layers.Flatten(name='polflat')(rnl)\n",
    "        fc=layers.Dense(units=self.action_space,name='polout',kernel_regularizer=regularizers.L2(0.0001))(flt)  \n",
    "        return fc\n",
    "\n",
    "    def valhead(self,input,nf):\n",
    "        c=layers.Conv2D(1,1,(1,1),'same',kernel_regularizer=regularizers.L2(0.0001))(input)\n",
    "        b=layers.BatchNormalization()(c)\n",
    "        rnl=layers.Activation(activation='softplus')(b)\n",
    "        flt=layers.Flatten()(rnl)\n",
    "        fcl=layers.Dense(nf,kernel_regularizer=regularizers.L2(0.0001))(flt)\n",
    "        rnl2=layers.Activation(activation='softplus')(fcl)\n",
    "        fcs=layers.Dense(1,kernel_regularizer=regularizers.L2(0.0001))(rnl2)\n",
    "        tanh=layers.Activation(activation='tanh',name='valout')(fcs)\n",
    "        return tanh    \n",
    "    \n",
    "    def build(self,n_res,nf,):\n",
    "        conv=self.convblock(self.inpt,nf)\n",
    "        restower=conv\n",
    "        for i in range(n_res):\n",
    "            restower=self.resblock(restower,i,nf)\n",
    "        polh=self.polhead(restower)\n",
    "        valh=self.valhead(restower,nf)\n",
    "        outputs=[polh,valh]\n",
    "        self.net=Model(self.inpt,outputs)\n",
    "        return\n",
    "\n",
    "    def summary(self):\n",
    "        self.net.summary()\n",
    "        return\n",
    "    \n",
    "    def compilar(self,lr=0.01):\n",
    "        self.net.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr,momentum=0.9),loss={'polout':tf.keras.losses.CategoricalCrossentropy(),'valout':tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "\n",
    "    # Funções logísticas para armazenamento e substituição de modelos\n",
    "    def copy_weights(self,bestname):\n",
    "        src=f'modelos/{self.game.name}/{str(len(self.game.board))}/best/{bestname}.h5'\n",
    "        dest=f'modelos/{self.game.name}/{str(len(self.game.board))}/{bestname}.h5'\n",
    "        copy(src, dest)\n",
    "    \n",
    "    def make_best(self):\n",
    "        os.remove((f'modelos/{self.game.name}/{str(len(self.game.board))}/best/{self.get_best_name()}.h5'))\n",
    "        self.net.save_weights(f'modelos/{self.game.name}/{str(len(self.game.board))}/best/{self.name}.h5')\n",
    "\n",
    "    def get_best_name(self):\n",
    "        folder_path = f\"modelos/{self.game.name}/{len(self.game.board)}/best\"\n",
    "        entries = os.listdir(folder_path)\n",
    "        for e in entries:\n",
    "            file_name = e\n",
    "            break\n",
    "        return file_name[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_name(game):\n",
    "    folder_path = f\"modelos/{game.name}/{len(game.board)}/best\"\n",
    "    entries = os.listdir(folder_path)\n",
    "    file_name = None\n",
    "    for e in entries:\n",
    "        file_name = e\n",
    "        break\n",
    "    return file_name[:-3]\n",
    "\n",
    "\n",
    "# Loss Function, igual à proposta no artigo original, em que o parâmetro de regularização está aplicado nas Layers e não explicitamente na Loss\n",
    "def sigmaloss(y_true,y_pred):\n",
    "        pol=y_pred[0]\n",
    "        pit=np.transpose(np.array(y_true[0]))\n",
    "        return (y_pred[1]-y_true[1])**2-np.dot(pit,np.log(pol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communications protocol of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move_go():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move_attaxx():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move(game_name):   # returns the move in the form \"MOVE X,Y\"\n",
    "    if game_name=='go':\n",
    "        return choose_move_go()\n",
    "    else:\n",
    "        return choose_move_attaxx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_server(host='localhost', port=12345):\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((host, port))\n",
    "\n",
    "    response = client_socket.recv(1024).decode()\n",
    "    print(f\"Server ResponseINIT: {response}\")\n",
    "\n",
    "    Game = response[-4:]\n",
    "    print(\"Playing:\", Game)\n",
    "    if Game[0]=='A':\n",
    "        game_name = 'attaxx'\n",
    "    else:\n",
    "        game_name = 'go'\n",
    "    n = int(Game[1])\n",
    "\n",
    "    if \"1\" in response:\n",
    "        ag=1\n",
    "    else:\n",
    "        ag=2\n",
    "    first=True\n",
    "\n",
    "    game_state=avaliar.makegame(Game)\n",
    "    teta=Neura(game_state,'Eakesgo7')\n",
    "    alpha=MCTS(game_state,ARGS,teta)\n",
    "\n",
    "    while True:\n",
    "        # Generate and send a random move\n",
    "        if ag == 1 or not first:\n",
    "            move = alpha.play()\n",
    "            time.sleep(1)\n",
    "            smove=str(move)\n",
    "            client_socket.send(smove.encode())\n",
    "            print(\"Send:\",move)\n",
    "        \n",
    "            # Wait for server response\n",
    "            response = client_socket.recv(1024).decode()\n",
    "            print(f\"Server Response1: {response}\")\n",
    "            if response == \"INVALID\":\n",
    "                continue\n",
    "            if \"END\" in response: break\n",
    "            game_state=game_state.move(move)\n",
    "            \n",
    "        first=False\n",
    "        response = client_socket.recv(1024).decode()\n",
    "        if response == \"PASS\":\n",
    "            game_state = game_state.pass_turn()\n",
    "        else:\n",
    "            i=response[5]\n",
    "            j=response[7]\n",
    "            if game_name == \"attaxx\":\n",
    "                i2=response[9]\n",
    "                j2=response[11]\n",
    "        action=(int(i),int(j))\n",
    "        print(f\"Server Response2: {response}\")\n",
    "        if \"END\" in response: break\n",
    "        game_state=game_state.move(action)\n",
    "        alpha.cut(action)\n",
    "\n",
    "    client_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    connect_to_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,   \n",
    "  Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel & Demis Hassabis. (2017, October 19).   \n",
    "    **Mastering the game of Go without human knowledge**. doi:10.1038/nature24270\n",
    "\n",
    "- Johannes Czech, Patrick Korus & Kristian Kersting. (2020, December 22)\n",
    "    **Monte-Carlo Graph Search for AlphaZero**. arXiv:2012.11045v1 [cs.AI] \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
