{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from MCTS import MCTS\n",
    "import tensorflow as tf\n",
    "import optimizar,avaliar,selfplay\n",
    "import Go,Attaxx\n",
    "from ioannina import Neura, get_best_name,exports,opts\n",
    "\n",
    "ARGS = {\n",
    "    'cpuct': 1.5,\n",
    "    'num_searches': 1600\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports()\n",
    "opts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira iteração (não se passa nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game=avaliar.makegame('G7x7')\n",
    "# rede=Neura(game,n_resblocks=19)\n",
    "# print(rede.summary())\n",
    "# rede2=Neura(game,n_resblocks=7)\n",
    "# print(rede2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de Jogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=MCTS(game,ARGS,rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCTS import MCTS\n",
    "import tensorflow as tf\n",
    "import optimizar,avaliar,selfplay\n",
    "import Go,Attaxx\n",
    "from ioannina import Neura, get_best_name,exports,opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game=avaliar.makegame('G9x9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não conseguiu localizar o caminho especificado: 'modelos/go/9/best'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m selfplay\u001b[38;5;241m.\u001b[39msp(game)\n\u001b[0;32m      2\u001b[0m optimizar\u001b[38;5;241m.\u001b[39mtrain(game)\n\u001b[0;32m      3\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m avaliar\u001b[38;5;241m.\u001b[39mavaliar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG9x9\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m9\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\Lab. IACD - project 2\\SigmaZero\\selfplay.py:26\u001b[0m, in \u001b[0;36msp\u001b[1;34m(game)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msp\u001b[39m(game):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m#game=makegame(games)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     teta\u001b[38;5;241m=\u001b[39mNeura(game,name\u001b[38;5;241m=\u001b[39mget_best_name(game))\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m):\n\u001b[0;32m     28\u001b[0m         alpha\u001b[38;5;241m=\u001b[39mMCTS(game,ARGS,teta)\n",
      "File \u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\Lab. IACD - project 2\\SigmaZero\\ioannina.py:143\u001b[0m, in \u001b[0;36mget_best_name\u001b[1;34m(game)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_name\u001b[39m(game):\n\u001b[0;32m    142\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(game\u001b[38;5;241m.\u001b[39mboard)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     entries \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path)\n\u001b[0;32m    144\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m entries:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não conseguiu localizar o caminho especificado: 'modelos/go/9/best'"
     ]
    }
   ],
   "source": [
    "selfplay.sp(game)\n",
    "optimizar.train(game)\n",
    "evaluation = avaliar.avaliar(\"G9x9\",9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "game=avaliar.makegame('G7x7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[ 0  0  0 -1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m selfplay\u001b[38;5;241m.\u001b[39msp(game)\n\u001b[0;32m      2\u001b[0m optimizar\u001b[38;5;241m.\u001b[39mtrain(game)\n\u001b[0;32m      3\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m avaliar\u001b[38;5;241m.\u001b[39mavaliar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG7x7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m7\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\Lab. IACD - project 2\\SigmaZero\\selfplay.py:29\u001b[0m, in \u001b[0;36msp\u001b[1;34m(game)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m):\n\u001b[0;32m     28\u001b[0m     alpha\u001b[38;5;241m=\u001b[39mMCTS(game,ARGS,teta)\n\u001b[1;32m---> 29\u001b[0m     winner\u001b[38;5;241m=\u001b[39magent_v_agent(game,alpha,alpha,\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\Lab. IACD - project 2\\SigmaZero\\avaliar.py:31\u001b[0m, in \u001b[0;36magent_v_agent\u001b[1;34m(game, alphai, alphas, sp)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m game\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Attaxx\u001b[38;5;241m.\u001b[39magent_v_agent(game,alphai,alphas,sp)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Go\u001b[38;5;241m.\u001b[39magent_v_agent(game,alphai,alphas,sp)\n",
      "File \u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\Lab. IACD - project 2\\SigmaZero\\Go.py:322\u001b[0m, in \u001b[0;36magent_v_agent\u001b[1;34m(game, alphai, alphas, sp)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m    321\u001b[0m     turn\u001b[38;5;241m=\u001b[39mswitchPlayer(turn)\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m turn\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    324\u001b[0m     action,policy \u001b[38;5;241m=\u001b[39m alphai\u001b[38;5;241m.\u001b[39mplay()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "selfplay.sp(game)\n",
    "optimizar.train(game)\n",
    "evaluation = avaliar.avaliar(\"G7x7\",7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
